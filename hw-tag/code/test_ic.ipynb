{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#!/usr/bin/env python3"]},{"cell_type":"markdown","metadata":{},"source":["This file illustrates how you might experiment with the HMM interface.\n","You can paste these commands in at the Python prompt, or execute `test_ic.py` directly.\n","A notebook interface is nicer than the plain Python prompt, so we provide\n","a notebook version of this file as `test_ic.ipynb`, which you can open with\n","`jupyter` or with Visual Studio `code` (run it with the `nlp-class` kernel)."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import logging, math, os\n","from pathlib import Path"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch\n","from torch import tensor"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from corpus import TaggedCorpus\n","from eval import model_cross_entropy, write_tagging\n","from hmm import HiddenMarkovModel\n","from crf import ConditionalRandomField"]},{"cell_type":"markdown","metadata":{},"source":["Set up logging."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["log = logging.getLogger(\"test_ic\")       # For usage, see findsim.py in earlier assignment.\n","logging.root.setLevel(level=logging.INFO)\n","logging.basicConfig(level=logging.INFO)  # could change INFO to DEBUG\n","# torch.autograd.set_detect_anomaly(True)    # uncomment to improve error messages from .backward(), but slows down"]},{"cell_type":"markdown","metadata":{},"source":["Switch working directory to the directory where the data live.  You may want to edit this line."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["os.chdir(\"../data\")"]},{"cell_type":"markdown","metadata":{},"source":["Get vocabulary and tagset from a supervised corpus."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:corpus:Read 40 tokens from icsup\n","INFO:corpus:Created 4 tag types\n","INFO:corpus:Created 5 word types\n","INFO:test_ic:Ice cream vocabulary: ['1', '2', '3', '_EOS_WORD_', '_BOS_WORD_']\n","INFO:test_ic:Ice cream tagset: ['C', 'H', '_EOS_TAG_', '_BOS_TAG_']\n"]}],"source":["icsup = TaggedCorpus(Path(\"icsup\"), add_oov=False)\n","log.info(f\"Ice cream vocabulary: {list(icsup.vocab)}\")\n","log.info(f\"Ice cream tagset: {list(icsup.tagset)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Two ways to look at the corpus ..."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/C 1/C 1/C 1/C 1/C 1/C 1/C 2/C 2/C 3/H\n","1/H 2/H 2/H 3/H 3/H 3/H 3/H 3/H 3/H 3/C\n","1/C 1/C 1/C 1/C 1/C 1/C 1/C 2/C 2/C 3/H\n","1/H 2/H 2/H 3/H 3/H 3/H 3/H 3/H 3/H 3/C\n"]},{"data":{"text/plain":["0"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["os.system(\"cat icsup\")   # call the shell to look at the file directly"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:1/C 1/C 1/C 1/C 1/C 1/C 1/C 2/C 2/C 3/H\n","1/H 2/H 2/H 3/H 3/H 3/H 3/H 3/H 3/H 3/C\n","1/C 1/C 1/C 1/C 1/C 1/C 1/C 2/C 2/C 3/H\n","1/H 2/H 2/H 3/H 3/H 3/H 3/H 3/H 3/H 3/C\n"]}],"source":["log.info(icsup)          # print the TaggedCorpus python object we constructed from it"]},{"cell_type":"markdown","metadata":{},"source":["Make an HMM."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Hidden Markov Model (HMM) test\n","\n","INFO:test_ic:*** Current A, B matrices (using initalizations from the ice cream spreadsheet)\n"]},{"name":"stdout","output_type":"stream","text":["Transition matrix A:\n","\tC\tH\t_EOS_TAG_\t_BOS_TAG_\n","C\t0.800\t0.100\t0.100\t0.000\n","H\t0.100\t0.800\t0.100\t0.000\n","_EOS_TAG_\t0.000\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.500\t0.500\t0.000\t0.000\n","\n","Emission matrix B:\n","\t1\t2\t3\n","C\t0.700\t0.200\t0.100\n","H\t0.100\t0.200\t0.700\n","_EOS_TAG_\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.000\t0.000\t0.000\n","\n","\n"]}],"source":["log.info(\"*** Hidden Markov Model (HMM) test\\n\")\n","hmm = HiddenMarkovModel(icsup.tagset, icsup.vocab)\n","# Change the transition/emission initial probabilities to match the ice cream spreadsheet,\n","# and test your implementation of the Viterbi algorithm.  Note that the spreadsheet \n","# uses transposed versions of these matrices.\n","hmm.B = tensor([[0.7000, 0.2000, 0.1000],    # emission probabilities\n","                [0.1000, 0.2000, 0.7000],\n","                [0.0000, 0.0000, 0.0000],\n","                [0.0000, 0.0000, 0.0000]])\n","hmm.A = tensor([[0.8000, 0.1000, 0.1000, 0.0000],   # transition probabilities\n","                [0.1000, 0.8000, 0.1000, 0.0000],\n","                [0.0000, 0.0000, 0.0000, 0.0000],\n","                [0.5000, 0.5000, 0.0000, 0.0000]])\n","log.info(\"*** Current A, B matrices (using initalizations from the ice cream spreadsheet)\")\n","hmm.printAB()"]},{"cell_type":"markdown","metadata":{},"source":["Try it out on the raw data from the spreadsheet, available in `icraw``."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Viterbi results on icraw with hard coded parameters\n","100%|██████████| 1/1 [00:00<00:00, 121.83it/s]"]},{"name":"stdout","output_type":"stream","text":["2/H 3/H 3/H 2/H 3/H 2/H 3/H 2/H 2/H 3/H 1/H 3/H 3/H 1/C 1/C 1/C 2/C 1/C 1/C 1/C 3/C 1/C 2/C 1/C 1/C 1/C 2/H 3/H 3/H 2/H 3/H 2/H 2/H\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["log.info(\"*** Viterbi results on icraw with hard coded parameters\")\n","icraw = TaggedCorpus(Path(\"icraw\"), tagset=icsup.tagset, vocab=icsup.vocab)\n","write_tagging(hmm, icraw, Path(\"icraw_hmm.output\"))  # calls hmm.viterbi_tagging on each sentence\n","os.system(\"cat icraw_hmm.output\")   # print the file we just created, and remove it\n"]},{"cell_type":"markdown","metadata":{},"source":["Did the parameters that we guessed above get the \"correct\" answer, \n","as revealed in `icdev`?"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Compare to icdev corpus:\n","2/H 3/H 3/H 2/H 3/H 2/H 3/H 2/H 2/H 3/H 1/C 3/C 3/C 1/C 1/C 1/C 2/C 1/C 1/C 1/C 3/C 1/C 2/C 1/C 1/C 1/C 2/H 3/H 3/H 2/H 3/H 2/H 2/H\n","100%|██████████| 1/1 [00:00<00:00, 132.40it/s]\n","INFO:eval:Tagging accuracy: all: 90.909%, seen: 90.909%, novel: nan%\n"]},{"data":{"text/plain":["0.09090909090909094"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["icdev = TaggedCorpus(Path(\"icdev\"), tagset=icsup.tagset, vocab=icsup.vocab)\n","log.info(f\"*** Compare to icdev corpus:\\n{icdev}\")\n","from eval import viterbi_error_rate\n","viterbi_error_rate(hmm, icdev, show_cross_entropy=False)"]},{"cell_type":"markdown","metadata":{},"source":["Now let's try your training code, running it on supervised data.\n","To test this, we'll restart from a random initialization.\n","(You could also try creating this new model with `unigram=true`, \n","which will affect the rest of the notebook.)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** A, B matrices as randomly initialized close to uniform\n"]},{"name":"stdout","output_type":"stream","text":["Transition matrix A:\n","\tC\tH\t_EOS_TAG_\t_BOS_TAG_\n","C\t0.334\t0.334\t0.332\t0.000\n","H\t0.334\t0.332\t0.334\t0.000\n","_EOS_TAG_\t0.334\t0.333\t0.333\t0.000\n","_BOS_TAG_\t0.333\t0.334\t0.334\t0.000\n","\n","Emission matrix B:\n","\t1\t2\t3\n","C\t0.333\t0.335\t0.332\n","H\t0.333\t0.333\t0.334\n","_EOS_TAG_\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.000\t0.000\t0.000\n","\n","\n"]}],"source":["hmm = HiddenMarkovModel(icsup.tagset, icsup.vocab)\n","log.info(\"*** A, B matrices as randomly initialized close to uniform\")\n","hmm.printAB()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Supervised training on icsup\n","100%|██████████| 4/4 [00:00<00:00, 823.42it/s]\n","INFO:eval:Cross-entropy: 1.4671 nats (= perplexity 4.337)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -16.1357421875\n","Z (prob): 9.825082258885232e-08\n","log_Z: -16.141292572021484\n","Z (prob): 9.770700870603832e-08\n","log_Z: -16.1357421875\n","Z (prob): 9.825082258885232e-08\n","log_Z: -16.141292572021484\n","Z (prob): 9.770700870603832e-08\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 389.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -16.1357421875\n","Z (prob): 9.825082258885232e-08\n","Warning: log_Z from forward pass (-16.1357421875) and backward pass (-15.441454887390137) do not match.\n","log_Z: -16.141292572021484\n","Z (prob): 9.770700870603832e-08\n","Warning: log_Z from forward pass (-16.141292572021484) and backward pass (-15.447007179260254) do not match.\n","log_Z: -16.1357421875\n","Z (prob): 9.825082258885232e-08\n","Warning: log_Z from forward pass (-16.1357421875) and backward pass (-15.441454887390137) do not match.\n","log_Z: -16.141292572021484\n","Z (prob): 9.770700870603832e-08\n","Warning: log_Z from forward pass (-16.141292572021484) and backward pass (-15.447007179260254) do not match.\n","\n","Expected counts A:\n","tensor([[16.,  2.,  2.,  0.],\n","        [ 2., 16.,  2.,  0.],\n","        [ 0.,  0.,  0.,  0.],\n","        [ 2.,  2.,  0.,  0.]])\n","\n","Expected counts B:\n","tensor([[14.,  4.,  2.],\n","        [ 2.,  4., 14.],\n","        [ 0.,  0.,  0.],\n","        [ 0.,  0.,  0.]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 925.08it/s]\n","INFO:eval:Cross-entropy: 1.0584 nats (= perplexity 2.882)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -11.642183303833008\n","Z (prob): 8.787473234406207e-06\n","log_Z: -11.642181396484375\n","Z (prob): 8.78749051480554e-06\n","log_Z: -11.642183303833008\n","Z (prob): 8.787473234406207e-06\n","log_Z: -11.642181396484375\n","Z (prob): 8.78749051480554e-06\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 339.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -11.642183303833008\n","Z (prob): 8.787473234406207e-06\n","Warning: log_Z from forward pass (-11.642183303833008) and backward pass (-11.05439567565918) do not match.\n","log_Z: -11.642181396484375\n","Z (prob): 8.78749051480554e-06\n","Warning: log_Z from forward pass (-11.642181396484375) and backward pass (-11.054394721984863) do not match.\n","log_Z: -11.642183303833008\n","Z (prob): 8.787473234406207e-06\n","Warning: log_Z from forward pass (-11.642183303833008) and backward pass (-11.05439567565918) do not match.\n","log_Z: -11.642181396484375\n","Z (prob): 8.78749051480554e-06\n","Warning: log_Z from forward pass (-11.642181396484375) and backward pass (-11.054394721984863) do not match.\n","\n","Expected counts A:\n","tensor([[16.,  2.,  2.,  0.],\n","        [ 2., 16.,  2.,  0.],\n","        [ 0.,  0.,  0.,  0.],\n","        [ 2.,  2.,  0.,  0.]])\n","\n","Expected counts B:\n","tensor([[14.,  4.,  2.],\n","        [ 2.,  4., 14.],\n","        [ 0.,  0.,  0.],\n","        [ 0.,  0.,  0.]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 930.41it/s]\n","INFO:eval:Cross-entropy: 1.0584 nats (= perplexity 2.882)\n","INFO:hmm:Saving model to my_hmm.pkl\n","INFO:hmm:Saved model to my_hmm.pkl\n","INFO:test_ic:*** A, B matrices after training on icsup (should match initial params on spreadsheet [transposed])\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -11.642183303833008\n","Z (prob): 8.787473234406207e-06\n","log_Z: -11.642181396484375\n","Z (prob): 8.78749051480554e-06\n","log_Z: -11.642183303833008\n","Z (prob): 8.787473234406207e-06\n","log_Z: -11.642181396484375\n","Z (prob): 8.78749051480554e-06\n","Transition matrix A:\n","\tC\tH\t_EOS_TAG_\t_BOS_TAG_\n","C\t0.800\t0.100\t0.100\t0.000\n","H\t0.100\t0.800\t0.100\t0.000\n","_EOS_TAG_\t0.000\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.500\t0.500\t0.000\t0.000\n","\n","Emission matrix B:\n","\t1\t2\t3\n","C\t0.700\t0.200\t0.100\n","H\t0.100\t0.200\t0.700\n","_EOS_TAG_\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.000\t0.000\t0.000\n","\n","\n"]}],"source":["log.info(\"*** Supervised training on icsup\")\n","cross_entropy_loss = lambda model: model_cross_entropy(model, icsup)\n","hmm.train(corpus=icsup, loss=cross_entropy_loss, tolerance=0.0001)\n","log.info(\"*** A, B matrices after training on icsup (should \"\n","         \"match initial params on spreadsheet [transposed])\")\n","hmm.printAB()"]},{"cell_type":"markdown","metadata":{},"source":["Now that we've reached the spreadsheet's starting guess, let's again tag\n","the spreadsheet \"sentence\" (that is, the sequence of ice creams) using the\n","Viterbi algorithm."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Viterbi results on icraw\n","100%|██████████| 1/1 [00:00<00:00, 121.55it/s]"]},{"name":"stdout","output_type":"stream","text":["2/H 3/H 3/H 2/H 3/H 2/H 3/H 2/H 2/H 3/H 1/H 3/H 3/H 1/C 1/C 1/C 2/C 1/C 1/C 1/C 3/C 1/C 2/C 1/C 1/C 1/C 2/H 3/H 3/H 2/H 3/H 2/H 2/H\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["log.info(\"*** Viterbi results on icraw\")\n","icraw = TaggedCorpus(Path(\"icraw\"), tagset=icsup.tagset, vocab=icsup.vocab)\n","write_tagging(hmm, icraw, Path(\"icraw_hmm.output\"))  # calls hmm.viterbi_tagging on each sentence\n","os.system(\"cat icraw_hmm.output\")   # print the file we just created, and remove it"]},{"cell_type":"markdown","metadata":{},"source":["Next let's use the forward algorithm to see what the model thinks about \n","the probability of the spreadsheet \"sentence.\""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Forward algorithm on icraw (should approximately match iteration 0 on spreadsheet)\n","INFO:test_ic:9.12755498101095e-19 = p(2 3 3 2 3 2 3 2 2 3 1 3 3 1 1 1 2 1 1 1 3 1 2 1 1 1 2 3 3 2 3 2 2)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -41.537818908691406\n","Z (prob): 9.127554454513589e-19\n"]}],"source":["log.info(\"*** Forward algorithm on icraw (should approximately match iteration 0 \"\n","             \"on spreadsheet)\")\n","for sentence in icraw:\n","    prob = math.exp(hmm.logprob(sentence, icraw))\n","    log.info(f\"{prob} = p({sentence})\")"]},{"cell_type":"markdown","metadata":{},"source":["Finally, let's reestimate on the icraw data, as the spreadsheet does.\n","We'll evaluate as we go along on the *training* perplexity, and stop\n","when that has more or less converged."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Reestimating on icraw (perplexity should improve on every iteration)\n","100%|██████████| 1/1 [00:00<00:00, 264.61it/s]\n","INFO:eval:Cross-entropy: 1.2217 nats (= perplexity 3.393)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -41.537818908691406\n","Z (prob): 9.127554454513589e-19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 79.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -41.537818908691406\n","Z (prob): 9.127554454513589e-19\n","Warning: log_Z from forward pass (-41.537818908691406) and backward pass (-40.95003128051758) do not match.\n","\n","Expected counts A:\n","tensor([[1.8163e+18, 2.2598e+17, 3.1730e+16, 0.0000e+00],\n","        [2.3948e+17, 2.2395e+18, 1.0956e+17, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [1.8234e+16, 1.2305e+17, 0.0000e+00, 0.0000e+00]])\n","\n","Expected counts B:\n","tensor([[3.8400e+18, 2.8772e+18, 1.7099e+18],\n","        [1.2676e+18, 7.2802e+18, 3.1618e+18],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 293.62it/s]\n","INFO:eval:Cross-entropy: 1.1590 nats (= perplexity 3.187)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -39.40589141845703\n","Z (prob): 7.695535035363572e-18\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["log_Z: -39.40589141845703\n","Z (prob): 7.695535035363572e-18\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 73.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Warning: log_Z from forward pass (-39.40589141845703) and backward pass (-39.120426177978516) do not match.\n","\n","Expected counts A:\n","tensor([[9.9021e+16, 8.1350e+15, 4.5800e+14, 0.0000e+00],\n","        [8.3952e+15, 7.5103e+16, 5.4999e+15, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [1.9777e+14, 5.7602e+15, 0.0000e+00, 0.0000e+00]])\n","\n","Expected counts B:\n","tensor([[1.8276e+17, 5.9987e+16, 1.1689e+17],\n","        [1.8828e+16, 8.6304e+16, 1.7975e+17],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 298.25it/s]\n","INFO:eval:Cross-entropy: 1.1202 nats (= perplexity 3.065)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -38.086204528808594\n","Z (prob): 2.879861066338888e-17\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 78.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -38.086204528808594\n","Z (prob): 2.879861066338888e-17\n","Warning: log_Z from forward pass (-38.086204528808594) and backward pass (-38.015350341796875) do not match.\n","\n","Expected counts A:\n","tensor([[3.5568e+16, 2.6680e+15, 3.3981e+13, 0.0000e+00],\n","        [2.6929e+15, 2.8827e+16, 2.1459e+15, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [9.0099e+12, 2.1709e+15, 0.0000e+00, 0.0000e+00]])\n","\n","Expected counts B:\n","tensor([[6.2818e+16, 4.1117e+16, 2.1642e+16],\n","        [5.2492e+15, 6.7541e+16, 3.4567e+16],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 331.88it/s]\n","INFO:eval:Cross-entropy: 1.1069 nats (= perplexity 3.025)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.63473892211914\n","Z (prob): 4.523145350426123e-17\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.63473892211914\n","Z (prob): 4.523145350426123e-17\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Warning: log_Z from forward pass (-37.63473892211914) and backward pass (-37.5950927734375) do not match.\n","\n","Expected counts A:\n","tensor([[2.3372e+16, 1.6499e+15, 3.9290e+12, 0.0000e+00],\n","        [1.6531e+15, 1.8545e+16, 1.4092e+15, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [6.4254e+11, 1.4125e+15, 0.0000e+00, 0.0000e+00]])\n","\n","Expected counts B:\n","tensor([[4.3570e+16, 1.3288e+16, 2.7800e+16],\n","        [3.0565e+15, 2.1327e+16, 4.2337e+16],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 298.42it/s]\n","INFO:eval:Cross-entropy: 1.1065 nats (= perplexity 3.024)\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.620330810546875\n","Z (prob): 4.588787095115881e-17\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.620330810546875\n","Z (prob): 4.588787095115881e-17\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 70.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Warning: log_Z from forward pass (-37.620330810546875) and backward pass (-37.60268020629883) do not match.\n","\n","Expected counts A:\n","tensor([[2.3283e+16, 1.6348e+15, 5.7773e+11, 0.0000e+00],\n","        [1.6353e+15, 1.8945e+16, 1.4212e+15, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [5.9646e+10, 1.4218e+15, 0.0000e+00, 0.0000e+00]])\n","\n","Expected counts B:\n","tensor([[4.3928e+16, 2.6956e+16, 1.4142e+16],\n","        [3.2185e+15, 4.2963e+16, 2.2140e+16],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 198.58it/s]"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.468162536621094\n","Z (prob): 5.34298258437315e-17\n"]},{"name":"stderr","output_type":"stream","text":["\n","INFO:eval:Cross-entropy: 1.1020 nats (= perplexity 3.010)\n","100%|██████████| 1/1 [00:00<00:00, 82.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.468162536621094\n","Z (prob): 5.34298258437315e-17\n","Warning: log_Z from forward pass (-37.468162536621094) and backward pass (-37.44669723510742) do not match.\n","\n","Expected counts A:\n","tensor([[1.9803e+16, 1.3847e+15, 7.5664e+10, 0.0000e+00],\n","        [1.3847e+15, 1.6118e+16, 1.2090e+15, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [4.7762e+09, 1.2091e+15, 0.0000e+00, 0.0000e+00]])\n","\n","Expected counts B:\n","tensor([[3.7591e+16, 1.1412e+16, 2.3431e+16],\n","        [2.8796e+15, 1.8425e+16, 3.6923e+16],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 281.29it/s]\n","INFO:eval:Cross-entropy: 1.1070 nats (= perplexity 3.025)\n","INFO:hmm:Saving model to my_hmm.pkl\n","INFO:hmm:Saved model to my_hmm.pkl\n"]},{"name":"stdout","output_type":"stream","text":["log_Z: -37.637115478515625\n","Z (prob): 4.51240887694743e-17\n"]}],"source":["log.info(\"*** Reestimating on icraw (perplexity should improve on every iteration)\")\n","negative_log_likelihood = lambda model: model_cross_entropy(model, icraw)  # evaluate on icraw itself\n","hmm.train(corpus=icraw, loss=negative_log_likelihood, tolerance=0.0001)\n","for sentence in icraw:\n","    prob = math.exp(hmm.logprob(sentence, icraw))\n","    log.info(f\"{prob} = p({sentence})\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** A, B matrices after reestimation on icrawshould match final params on spreadsheet [transposed])\n"]},{"name":"stdout","output_type":"stream","text":["Transition matrix A:\n","\tC\tH\t_EOS_TAG_\t_BOS_TAG_\n","C\t0.935\t0.065\t0.000\t0.000\n","H\t0.074\t0.861\t0.065\t0.000\n","_EOS_TAG_\t0.000\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.000\t1.000\t0.000\t0.000\n","\n","Emission matrix B:\n","\t1\t2\t3\n","C\t0.519\t0.158\t0.323\n","H\t0.049\t0.316\t0.634\n","_EOS_TAG_\t0.000\t0.000\t0.000\n","_BOS_TAG_\t0.000\t0.000\t0.000\n","\n","\n"]}],"source":["log.info(\"*** A, B matrices after reestimation on icraw\"\n","         \"should match final params on spreadsheet [transposed])\")\n","hmm.printAB()"]},{"cell_type":"markdown","metadata":{},"source":["Now let's try out a randomly initialized CRF on the ice cream data. Notice how\n","the initialized A and B matrices now hold non-negative potentials,\n","rather than probabilities that sum to 1."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:test_ic:*** Conditional Random Field (CRF) test\n","\n"]},{"ename":"NotImplementedError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Conditional Random Field (CRF) test\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m crf \u001b[38;5;241m=\u001b[39m \u001b[43mConditionalRandomField\u001b[49m\u001b[43m(\u001b[49m\u001b[43micsup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micsup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Current A, B matrices (potentials from small random parameters)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m crf\u001b[38;5;241m.\u001b[39mprintAB()\n","File \u001b[0;32m~/jhu/senior_year/nlp/nlp-hw-6/NLP_HW6/hw-tag/code/crf.py:55\u001b[0m, in \u001b[0;36mConditionalRandomField.__init__\u001b[0;34m(self, tagset, vocab, unigram)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     48\u001b[0m              tagset: Integerizer[Tag],\n\u001b[1;32m     49\u001b[0m              vocab: Integerizer[Word],\n\u001b[1;32m     50\u001b[0m              unigram: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct an CRF with initially random parameters, with the\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    given tagset, vocabulary, and lexical features.  See the super()\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    method for discussion.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtagset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munigram\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/jhu/senior_year/nlp/nlp-hw-6/NLP_HW6/hw-tag/code/hmm.py:83\u001b[0m, in \u001b[0;36mHiddenMarkovModel.__init__\u001b[0;34m(self, tagset, vocab, unigram)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m# we need this to exist\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meye: Tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)  \u001b[38;5;66;03m# identity matrix, used as a collection of one-hot tag vectors\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/jhu/senior_year/nlp/nlp-hw-6/NLP_HW6/hw-tag/code/crf.py:68\u001b[0m, in \u001b[0;36mConditionalRandomField.init_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params self.WA and self.WB to small random values, and\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mthen compute the potential matrices A, B from them.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mAs in the parent method, we respect structural zeroes (\"Don't guess when you know\").\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# See the \"Training CRFs\" section of the reading handout.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# For a unigram model, self.WA should just have a single row:\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# that model has fewer parameters.\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m   \u001b[38;5;66;03m# you fill this in!\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdateAB()\n","\u001b[0;31mNotImplementedError\u001b[0m: "]}],"source":["log.info(\"*** Conditional Random Field (CRF) test\\n\")\n","crf = ConditionalRandomField(icsup.tagset, icsup.vocab)\n","log.info(\"*** Current A, B matrices (potentials from small random parameters)\")\n","crf.printAB()"]},{"cell_type":"markdown","metadata":{},"source":["Now let's try your training code, running it on supervised data. To test this,\n","we'll restart from a random initialization. \n","\n","Note that the logger reports the CRF's *conditional* cross-entropy, \n","log p(tags | words) / n.  This is much lower than the HMM's *joint* \n","cross-entropy log p(tags, words) / n, but that doesn't mean the CRF\n","is worse at tagging.  The CRF is just predicting less information."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log.info(\"*** Supervised training on icsup\")\n","cross_entropy_loss = lambda model: model_cross_entropy(model, icsup)\n","crf.train(corpus=icsup, loss=cross_entropy_loss, lr=0.1, tolerance=0.0001)\n","log.info(\"*** A, B matrices after training on icsup\")\n","crf.printAB()"]},{"cell_type":"markdown","metadata":{},"source":["Let's again tag the spreadsheet \"sentence\" (that is, the sequence of ice creams) \n","using the Viterbi algorithm (this may not match the HMM)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log.info(\"*** Viterbi results on icraw with trained parameters\")\n","icraw = TaggedCorpus(Path(\"icraw\"), tagset=icsup.tagset, vocab=icsup.vocab)\n","write_tagging(hmm, icraw, Path(\"icraw_crf.output\"))  # calls hmm.viterbi_tagging on each sentence\n","os.system(\"cat icraw_crf.output\")   # print the file we just created, and remove it"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":2}
